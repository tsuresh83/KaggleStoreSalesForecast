{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cloudpickle as cpkl\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from functools import reduce\n",
    "from fbprophet import Prophet\n",
    "import multiprocessing as mp\n",
    "from itertools import repeat\n",
    "from joblib import Parallel, delayed\n",
    "import calendar\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_var_dict = {'store_nbr': 10, 'item_nbr': 50, 'Year': 2, 'Month': 6,\n",
    "'Day': 10, 'Week': 2,'holiday': 3, 'onpromotion_x': 3, 'salary_day':3,\n",
    "'city': 6, 'state': 5, 'type_x': 3, 'cluster': 5,'type_y':3,'locale':5,  \n",
    "'family': 10, 'class': 20, 'perishable' :3,\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_vars = ['onpromotion_bw', 'onpromotion_fw','holiday_bw', 'holiday_fw','dcoilwtico','transactions',\n",
    "               'Afterholiday', 'Beforeholiday','Afteronpromotion', 'Beforeonpromotion']\n",
    "cat_vars = [o[0] for o in \n",
    "            sorted(cat_var_dict.items(), key=operator.itemgetter(1), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datatypes = {'id':np.uint32,'date':str,'store_nbr':np.uint8,'item_nbr':np.uint32,\n",
    "            'unit_sales':np.float32,'onpromotion_x':np.uint8,'salary_day':np.uint8,\n",
    "            'holiday':np.uint8,'Afterholiday':np.int16,'Beforeholiday':np.int16,\n",
    "            'holiday_bw':np.int8,'holiday_fw':np.int8,'Afteronpromotion':np.int16,\n",
    "            'Beforeonpromotion':np.int16,'onpromotion_bw':np.int8,'onpromotion_fw':np.int8,\n",
    "            'city':str,'state':str,'type_x':str,'cluster':np.uint8,'family':str,\n",
    "            'class':np.uint16,'perishable':np.uint8,'type_y':str,'locale':str,\n",
    "            'dcoilwtico':np.float16,'transactions':np.float32,'Year':np.uint16,\n",
    "            'Month':np.uint8,'Week':np.uint8,'Day':np.uint8}\n",
    "date_cols = ['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suresh/.local/lib/python3.5/site-packages/numpy/lib/arraysetops.py:395: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "joined = pd.read_csv(\"results/joined.csv\",index_col=0,usecols=datatypes.keys(),dtype=datatypes,parse_dates=date_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'store_nbr', 'item_nbr', 'unit_sales', 'onpromotion_x',\n",
      "       'salary_day', 'holiday', 'Afterholiday', 'Beforeholiday', 'holiday_bw',\n",
      "       'holiday_fw', 'Afteronpromotion', 'Beforeonpromotion', 'onpromotion_bw',\n",
      "       'onpromotion_fw', 'city', 'state', 'type_x', 'cluster', 'family',\n",
      "       'class', 'perishable', 'type_y', 'locale', 'dcoilwtico', 'transactions',\n",
      "       'Year', 'Month', 'Week', 'Day'],\n",
      "      dtype='object')\n",
      "['2015-01-03T00:00:00.000000000' '2015-01-04T00:00:00.000000000'\n",
      " '2015-01-10T00:00:00.000000000' '2015-01-11T00:00:00.000000000'\n",
      " '2015-01-17T00:00:00.000000000' '2015-01-18T00:00:00.000000000'\n",
      " '2015-01-24T00:00:00.000000000' '2015-01-25T00:00:00.000000000'\n",
      " '2015-01-31T00:00:00.000000000' '2015-02-01T00:00:00.000000000'\n",
      " '2015-02-07T00:00:00.000000000' '2015-02-08T00:00:00.000000000'\n",
      " '2015-02-14T00:00:00.000000000' '2015-02-15T00:00:00.000000000'\n",
      " '2015-02-21T00:00:00.000000000' '2015-02-22T00:00:00.000000000'\n",
      " '2015-02-28T00:00:00.000000000' '2015-03-01T00:00:00.000000000'\n",
      " '2015-03-07T00:00:00.000000000' '2015-03-08T00:00:00.000000000'\n",
      " '2015-03-14T00:00:00.000000000' '2015-03-15T00:00:00.000000000'\n",
      " '2015-03-21T00:00:00.000000000' '2015-03-22T00:00:00.000000000'\n",
      " '2015-03-28T00:00:00.000000000' '2015-03-29T00:00:00.000000000'\n",
      " '2015-04-04T00:00:00.000000000' '2015-04-05T00:00:00.000000000'\n",
      " '2015-04-11T00:00:00.000000000' '2015-04-12T00:00:00.000000000'\n",
      " '2015-04-18T00:00:00.000000000' '2015-04-19T00:00:00.000000000'\n",
      " '2015-04-25T00:00:00.000000000' '2015-04-26T00:00:00.000000000'\n",
      " '2015-05-02T00:00:00.000000000' '2015-05-03T00:00:00.000000000'\n",
      " '2015-05-09T00:00:00.000000000' '2015-05-10T00:00:00.000000000'\n",
      " '2015-05-16T00:00:00.000000000' '2015-05-17T00:00:00.000000000'\n",
      " '2015-05-23T00:00:00.000000000' '2015-05-24T00:00:00.000000000'\n",
      " '2015-05-30T00:00:00.000000000' '2015-05-31T00:00:00.000000000'\n",
      " '2015-06-06T00:00:00.000000000' '2015-06-07T00:00:00.000000000'\n",
      " '2015-06-13T00:00:00.000000000' '2015-06-14T00:00:00.000000000'\n",
      " '2015-06-20T00:00:00.000000000' '2015-06-21T00:00:00.000000000'\n",
      " '2015-06-27T00:00:00.000000000' '2015-06-28T00:00:00.000000000'\n",
      " '2015-07-04T00:00:00.000000000' '2015-07-05T00:00:00.000000000'\n",
      " '2015-07-11T00:00:00.000000000' '2015-07-12T00:00:00.000000000'\n",
      " '2015-07-18T00:00:00.000000000' '2015-07-19T00:00:00.000000000'\n",
      " '2015-07-25T00:00:00.000000000' '2015-07-26T00:00:00.000000000'\n",
      " '2015-08-01T00:00:00.000000000' '2015-08-02T00:00:00.000000000'\n",
      " '2015-08-08T00:00:00.000000000' '2015-08-09T00:00:00.000000000'\n",
      " '2015-08-15T00:00:00.000000000' '2015-08-16T00:00:00.000000000'\n",
      " '2015-08-22T00:00:00.000000000' '2015-08-23T00:00:00.000000000'\n",
      " '2015-08-29T00:00:00.000000000' '2015-08-30T00:00:00.000000000'\n",
      " '2015-09-05T00:00:00.000000000' '2015-09-06T00:00:00.000000000'\n",
      " '2015-09-12T00:00:00.000000000' '2015-09-13T00:00:00.000000000'\n",
      " '2015-09-19T00:00:00.000000000' '2015-09-20T00:00:00.000000000'\n",
      " '2015-09-26T00:00:00.000000000' '2015-09-27T00:00:00.000000000'\n",
      " '2015-10-03T00:00:00.000000000' '2015-10-04T00:00:00.000000000'\n",
      " '2015-10-10T00:00:00.000000000' '2015-10-11T00:00:00.000000000'\n",
      " '2015-10-17T00:00:00.000000000' '2015-10-18T00:00:00.000000000'\n",
      " '2015-10-24T00:00:00.000000000' '2015-10-25T00:00:00.000000000'\n",
      " '2015-10-31T00:00:00.000000000' '2015-11-01T00:00:00.000000000'\n",
      " '2015-11-07T00:00:00.000000000' '2015-11-08T00:00:00.000000000'\n",
      " '2015-11-14T00:00:00.000000000' '2015-11-15T00:00:00.000000000'\n",
      " '2015-11-21T00:00:00.000000000' '2015-11-22T00:00:00.000000000'\n",
      " '2015-11-28T00:00:00.000000000' '2015-11-29T00:00:00.000000000'\n",
      " '2015-12-05T00:00:00.000000000' '2015-12-06T00:00:00.000000000'\n",
      " '2015-12-12T00:00:00.000000000' '2015-12-13T00:00:00.000000000'\n",
      " '2015-12-19T00:00:00.000000000' '2015-12-20T00:00:00.000000000'\n",
      " '2015-12-26T00:00:00.000000000' '2015-12-27T00:00:00.000000000'\n",
      " '2016-01-02T00:00:00.000000000' '2016-01-03T00:00:00.000000000'\n",
      " '2016-01-09T00:00:00.000000000' '2016-01-10T00:00:00.000000000'\n",
      " '2016-01-16T00:00:00.000000000' '2016-01-17T00:00:00.000000000'\n",
      " '2016-01-23T00:00:00.000000000' '2016-01-24T00:00:00.000000000'\n",
      " '2016-01-30T00:00:00.000000000' '2016-01-31T00:00:00.000000000'\n",
      " '2016-02-06T00:00:00.000000000' '2016-02-07T00:00:00.000000000'\n",
      " '2016-02-13T00:00:00.000000000' '2016-02-14T00:00:00.000000000'\n",
      " '2016-02-20T00:00:00.000000000' '2016-02-21T00:00:00.000000000'\n",
      " '2016-02-27T00:00:00.000000000' '2016-02-28T00:00:00.000000000'\n",
      " '2016-03-05T00:00:00.000000000' '2016-03-06T00:00:00.000000000'\n",
      " '2016-03-12T00:00:00.000000000' '2016-03-13T00:00:00.000000000'\n",
      " '2016-03-19T00:00:00.000000000' '2016-03-20T00:00:00.000000000'\n",
      " '2016-03-26T00:00:00.000000000' '2016-03-27T00:00:00.000000000'\n",
      " '2016-04-02T00:00:00.000000000' '2016-04-03T00:00:00.000000000'\n",
      " '2016-04-09T00:00:00.000000000' '2016-04-10T00:00:00.000000000'\n",
      " '2016-04-16T00:00:00.000000000' '2016-04-17T00:00:00.000000000'\n",
      " '2016-04-23T00:00:00.000000000' '2016-04-24T00:00:00.000000000'\n",
      " '2016-04-30T00:00:00.000000000' '2016-05-01T00:00:00.000000000'\n",
      " '2016-05-07T00:00:00.000000000' '2016-05-08T00:00:00.000000000'\n",
      " '2016-05-14T00:00:00.000000000' '2016-05-15T00:00:00.000000000'\n",
      " '2016-05-21T00:00:00.000000000' '2016-05-22T00:00:00.000000000'\n",
      " '2016-05-28T00:00:00.000000000' '2016-05-29T00:00:00.000000000'\n",
      " '2016-06-04T00:00:00.000000000' '2016-06-05T00:00:00.000000000'\n",
      " '2016-06-11T00:00:00.000000000' '2016-06-12T00:00:00.000000000'\n",
      " '2016-06-18T00:00:00.000000000' '2016-06-19T00:00:00.000000000'\n",
      " '2016-06-25T00:00:00.000000000' '2016-06-26T00:00:00.000000000'\n",
      " '2016-07-02T00:00:00.000000000' '2016-07-03T00:00:00.000000000'\n",
      " '2016-07-09T00:00:00.000000000' '2016-07-10T00:00:00.000000000'\n",
      " '2016-07-16T00:00:00.000000000' '2016-07-17T00:00:00.000000000'\n",
      " '2016-07-23T00:00:00.000000000' '2016-07-24T00:00:00.000000000'\n",
      " '2016-07-30T00:00:00.000000000' '2016-07-31T00:00:00.000000000'\n",
      " '2016-08-06T00:00:00.000000000' '2016-08-07T00:00:00.000000000'\n",
      " '2016-08-13T00:00:00.000000000' '2016-08-14T00:00:00.000000000'\n",
      " '2016-08-20T00:00:00.000000000' '2016-08-21T00:00:00.000000000'\n",
      " '2016-08-27T00:00:00.000000000' '2016-08-28T00:00:00.000000000'\n",
      " '2016-09-03T00:00:00.000000000' '2016-09-04T00:00:00.000000000'\n",
      " '2016-09-10T00:00:00.000000000' '2016-09-11T00:00:00.000000000'\n",
      " '2016-09-17T00:00:00.000000000' '2016-09-18T00:00:00.000000000'\n",
      " '2016-09-24T00:00:00.000000000' '2016-09-25T00:00:00.000000000'\n",
      " '2016-10-01T00:00:00.000000000' '2016-10-02T00:00:00.000000000'\n",
      " '2016-10-08T00:00:00.000000000' '2016-10-09T00:00:00.000000000'\n",
      " '2016-10-15T00:00:00.000000000' '2016-10-16T00:00:00.000000000'\n",
      " '2016-10-22T00:00:00.000000000' '2016-10-23T00:00:00.000000000'\n",
      " '2016-10-29T00:00:00.000000000' '2016-10-30T00:00:00.000000000'\n",
      " '2016-11-05T00:00:00.000000000' '2016-11-06T00:00:00.000000000'\n",
      " '2016-11-12T00:00:00.000000000' '2016-11-13T00:00:00.000000000'\n",
      " '2016-11-19T00:00:00.000000000' '2016-11-20T00:00:00.000000000'\n",
      " '2016-11-26T00:00:00.000000000' '2016-11-27T00:00:00.000000000'\n",
      " '2016-12-03T00:00:00.000000000' '2016-12-04T00:00:00.000000000'\n",
      " '2016-12-10T00:00:00.000000000' '2016-12-11T00:00:00.000000000'\n",
      " '2016-12-17T00:00:00.000000000' '2016-12-18T00:00:00.000000000'\n",
      " '2016-12-24T00:00:00.000000000' '2016-12-31T00:00:00.000000000'\n",
      " '2017-01-01T00:00:00.000000000' '2017-01-07T00:00:00.000000000'\n",
      " '2017-01-08T00:00:00.000000000' '2017-01-14T00:00:00.000000000'\n",
      " '2017-01-15T00:00:00.000000000' '2017-01-21T00:00:00.000000000'\n",
      " '2017-01-22T00:00:00.000000000' '2017-01-28T00:00:00.000000000'\n",
      " '2017-01-29T00:00:00.000000000' '2017-02-04T00:00:00.000000000'\n",
      " '2017-02-05T00:00:00.000000000' '2017-02-11T00:00:00.000000000'\n",
      " '2017-02-12T00:00:00.000000000' '2017-02-18T00:00:00.000000000'\n",
      " '2017-02-19T00:00:00.000000000' '2017-02-25T00:00:00.000000000'\n",
      " '2017-02-26T00:00:00.000000000' '2017-03-04T00:00:00.000000000'\n",
      " '2017-03-05T00:00:00.000000000' '2017-03-11T00:00:00.000000000'\n",
      " '2017-03-12T00:00:00.000000000' '2017-03-18T00:00:00.000000000'\n",
      " '2017-03-19T00:00:00.000000000' '2017-03-25T00:00:00.000000000'\n",
      " '2017-03-26T00:00:00.000000000' '2017-04-01T00:00:00.000000000'\n",
      " '2017-04-02T00:00:00.000000000' '2017-04-08T00:00:00.000000000'\n",
      " '2017-04-09T00:00:00.000000000' '2017-04-15T00:00:00.000000000'\n",
      " '2017-04-16T00:00:00.000000000' '2017-04-22T00:00:00.000000000'\n",
      " '2017-04-23T00:00:00.000000000' '2017-04-29T00:00:00.000000000'\n",
      " '2017-04-30T00:00:00.000000000' '2017-05-06T00:00:00.000000000'\n",
      " '2017-05-07T00:00:00.000000000' '2017-05-13T00:00:00.000000000'\n",
      " '2017-05-14T00:00:00.000000000' '2017-05-20T00:00:00.000000000'\n",
      " '2017-05-21T00:00:00.000000000' '2017-05-27T00:00:00.000000000'\n",
      " '2017-05-28T00:00:00.000000000' '2017-06-03T00:00:00.000000000'\n",
      " '2017-06-04T00:00:00.000000000' '2017-06-10T00:00:00.000000000'\n",
      " '2017-06-11T00:00:00.000000000' '2017-06-17T00:00:00.000000000'\n",
      " '2017-06-18T00:00:00.000000000' '2017-06-24T00:00:00.000000000'\n",
      " '2017-06-25T00:00:00.000000000' '2017-07-01T00:00:00.000000000'\n",
      " '2017-07-02T00:00:00.000000000' '2017-07-08T00:00:00.000000000'\n",
      " '2017-07-09T00:00:00.000000000' '2017-07-15T00:00:00.000000000'\n",
      " '2017-07-16T00:00:00.000000000' '2017-07-22T00:00:00.000000000'\n",
      " '2017-07-23T00:00:00.000000000' '2017-07-29T00:00:00.000000000'\n",
      " '2017-07-30T00:00:00.000000000' '2017-08-05T00:00:00.000000000'\n",
      " '2017-08-06T00:00:00.000000000' '2017-08-12T00:00:00.000000000'\n",
      " '2017-08-13T00:00:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "#te = pd.read_csv(\"results/joined.csv\",nrows=100,index_col=0)\n",
    "print(joined.columns)\n",
    "print(joined[joined.dcoilwtico.isnull()].date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in contin_vars: joined.ix[joined[v].isnull(), v] = 0\n",
    "for v in cat_vars: joined.ix[joined[v].isnull(), v] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_maps = [(o, LabelEncoder()) for o in cat_vars]\n",
    "contin_maps = [([o], StandardScaler()) for o in contin_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mapper = DataFrameMapper(cat_maps)\n",
    "cat_map_fit = cat_mapper.fit(joined)\n",
    "cat_cols = len(cat_map_fit.features)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_mapper = DataFrameMapper(contin_maps)\n",
    "contin_map_fit = contin_mapper.fit(joined)\n",
    "contin_cols = len(contin_map_fit.features)\n",
    "contin_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(contin_map_fit, open('results/contin_maps.pickle', 'wb'))\n",
    "pickle.dump(cat_map_fit, open('results/cat_maps.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined.set_index(\"date\",inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "train_size = int(len(joined) * train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_valid = joined[train_size:]\n",
    "joined_train = joined[:train_size]\n",
    "len(joined_valid), len(joined_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_preproc(dat):\n",
    "    return cat_map_fit.transform(dat).astype(np.int32)\n",
    "cat_map_train = cat_preproc(joined_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_map_valid = cat_preproc(joined_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contin_preproc(dat):\n",
    "    return contin_map_fit.transform(dat).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_map_train = contin_preproc(joined_train)\n",
    "contin_map_valid = contin_preproc(joined_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_orig = joined_train.unit_sales\n",
    "y_valid_orig = joined_valid.unit_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_log_y = np.max(np.log1p(joined.unit_sales))\n",
    "y_train = np.log1p(y_train_orig)/max_log_y\n",
    "y_valid = np.log1p(y_valid_orig)/max_log_y\n",
    "#y_train = np.log(y_train)\n",
    "#ymean=y_train_orig.mean()\n",
    "#ystd=y_train_orig.std()\n",
    "#y_train = (y_train_orig-ymean)/ystd\n",
    "#y_valid = np.log(y_valid)\n",
    "#y_valid = (y_valid_orig-ymean)/ystd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmspe(y_pred, targ = y_valid_orig):\n",
    "    pct_var = (targ - y_pred)/targ\n",
    "    return math.sqrt(np.square(pct_var).mean())\n",
    "def NWRMSLE(y, pred, wts,lt=False):\n",
    "    y = y.clip(0, y.max())\n",
    "    pred = pred.clip(0, pred.max())\n",
    "    #wts = np.full_like(y,wts)\n",
    "    #score = np.nansum(wts * ((np.log1p(pred) - np.log1p(y)) ** 2)) / wts.sum()\n",
    "    if lt:\n",
    "        score = np.nansum(wts * (np.subtract((pred), (y)) ** 2)) / wts.sum()\n",
    "    else:\n",
    "        score = np.nansum(wts * (np.subtract(np.log1p(pred), np.log1p(y)) ** 2)) / wts.sum()\n",
    "    return np.sqrt(score)\n",
    "def log_max_inv(preds, mx = max_log_y):\n",
    "    return np.exp(preds * mx)\n",
    "def normalize_inv(preds):\n",
    "    return preds * ystd + ymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (ymean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_cols(arr): return np.hsplit(arr,arr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_train = split_cols(cat_map_train) + [contin_map_train]\n",
    "#map_valid = split_cols(cat_map_valid) + [contin_map_valid]\n",
    "split_contins = True\n",
    "if split_contins:\n",
    "    map_train = split_cols(cat_map_train) + split_cols(contin_map_train)\n",
    "    map_valid = split_cols(cat_map_valid) + split_cols(contin_map_valid)\n",
    "else:\n",
    "    map_train = split_cols(cat_map_train) + [contin_map_train]\n",
    "    map_valid = split_cols(cat_map_valid) + [contin_map_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map_train = split_cols(cat_map_train) + split_cols(contin_map_train)\n",
    "#map_valid = split_cols(cat_map_valid) + split_cols(contin_map_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cat_map_info(feat): return feat[0], len(feat[1].classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_map_info(cat_map_fit.features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_init(scale):\n",
    "    return lambda shape, name=None: initializers.uniform(shape, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emb_init(shape, name=None): \n",
    "    return initializers.uniform(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "def get_emb(feat):\n",
    "    name, c = cat_map_info(feat)\n",
    "    #c2 = cat_var_dict[name]\n",
    "    c2 = (c+1)//2\n",
    "    if c2>100: c2=100\n",
    "    inp = Input((1,), dtype='int64', name=name+'_in')\n",
    "    # , W_regularizer=l2(1e-6)\n",
    "    # Embedding(vocabulary_size,output_size,input_length)\n",
    "    u = Flatten(name=name+'_flt')(Embedding(c, c2, input_length=1, embeddings_initializer='uniform')(inp))\n",
    "#     u = Flatten(name=name+'_flt')(Embedding(c, c2, input_length=1)(inp))\n",
    "    return inp,u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_contin(feat):\n",
    "    name = feat[0][0]\n",
    "    inp = Input((1,), name=name+'_in')\n",
    "    return inp, Dense(1, name=name+'_d')(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split_contins:\n",
    "    conts = [get_contin(feat) for feat in contin_map_fit.features]\n",
    "    cont_out = [d for inp,d in conts]\n",
    "    cont_inp = [inp for inp,d in conts]\n",
    "else:\n",
    "    contin_inp, contin_out = get_contin_one()\n",
    "    cont_out = [contin_out]\n",
    "    cont_inp = [contin_inp]\n",
    "#contin_inp = Input((contin_cols,), name='contin')\n",
    "#contin_out = Dense(contin_cols*10, activation='relu', name='contin_d')(contin_inp)\n",
    "\n",
    "#contin_out = BatchNormalization()(contin_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "embs = [get_emb(feat) for feat in cat_map_fit.features]\n",
    "#conts = [get_contin(feat) for feat in contin_map_fit.features]\n",
    "#contin_d = [d for inp,d in conts]\n",
    "x = merge([emb for inp,emb in embs] + cont_out, mode='concat')\n",
    "#x = merge([emb for inp,emb in embs] + contin_d, mode='concat')\n",
    "\n",
    "x = Dropout(0.02)(x)\n",
    "x = Dense(1000, activation='relu', init='uniform')(x)\n",
    "x = Dense(500, activation='relu', init='uniform')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model([inp for inp,emb in embs] + cont_inp, x)\n",
    "#model = Model([inp for inp,emb in embs] + [inp for inp,d in conts], x)\n",
    "model.compile('adam', 'mean_squared_error')\n",
    "#model.compile(Adam(), 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_map_train.shape)\n",
    "print(len(split_cols(cat_map_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "hist = model.fit(map_train, y_train, batch_size=512, nb_epoch=20,\n",
    "                 verbose=2, validation_data=(map_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_map_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = model.fit(map_train, y_train, batch_size=512, nb_epoch=20,\n",
    "                 verbose=2, validation_data=(map_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_map_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(split_cols(cat_map_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(split_cols(cat_map_train) + [contin_map_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.squeeze(model.predict(map_valid, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(preds,np.arange(0,100,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_map_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contin_vars)\n",
    "print(contin_map_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.dcoilwtico.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
